{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "parent_dir = os.path.dirname(os.getcwd())\n",
    "sys.path.append(parent_dir)\n",
    "sys.path.append(\"../models\")\n",
    "processed_series_path = Path(parent_dir) / 'processed_series'\n",
    "import copy\n",
    "from scipy.special import erf\n",
    "from scipy.stats import norm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "\n",
    "print(sys.path)\n",
    "from ICL import MultiResolutionPDF\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_files = sorted([path for path in processed_series_path.iterdir()], key=lambda x: x.name)\n",
    "for index, file in enumerate(all_files):\n",
    "    print(f\"[{index}]: {file.name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 1\n",
    "# alpha = 6\n",
    "\n",
    "file = all_files[0] # neighbor depth 2\n",
    "file = all_files[1] # neighbor depth 2\n",
    "file = all_files[2] # neighbor depth 2\n",
    "file = all_files[14] # neighbor depth 2\n",
    "# file = all_files[15] # neighbor depth 2\n",
    "# file = all_files[16] # neighbor depth 2\n",
    "# file = all_files[4] # all depth 1\n",
    "# file = all_files[127] # uncorrelated gaussian\n",
    "# file = all_files[129] # uncorrelated gaussian\n",
    "processed_dict = pickle.load(file.open('rb'))\n",
    "full_series = processed_dict['full_series']\n",
    "rescaled_true_mean_arr = processed_dict['rescaled_true_mean_arr']\n",
    "rescaled_true_sigma_arr = processed_dict['rescaled_true_sigma_arr']\n",
    "llama_size = processed_dict['llama_size']\n",
    "mode = processed_dict['mode']\n",
    "refine_depth = processed_dict['refine_depth']\n",
    "random_seed = processed_dict['random_seed']\n",
    "PDF_list = processed_dict['PDF_list']\n",
    "time_series = processed_dict['time_series']\n",
    "prec = processed_dict['prec']\n",
    "print(f\"seed: {processed_dict['random_seed']}\")\n",
    "print(f\"mode: {mode}\")\n",
    "print(f\"refine_depth: {refine_depth}\")\n",
    "print(f\"prec: {prec}\")\n",
    "print(f\"name: {file.stem}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### tune temperature \n",
    "\n",
    "for PDF in PDF_list:\n",
    "    if alpha != 1:\n",
    "        PDF.rescale_temperature(alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Calculate true discretized distribution: PDF_list_true\n",
    "### Compute discretized BT and KL loss\n",
    "\n",
    "PDF_true_list = copy.deepcopy(PDF_list)\n",
    "discrete_BT_loss = []\n",
    "discrete_KL_loss = []\n",
    "for PDF, PDF_true, true_mean, true_sigma in zip(PDF_list, PDF_true_list, rescaled_true_mean_arr, rescaled_true_sigma_arr):\n",
    "    def cdf(x):\n",
    "        return 0.5 * (1 + erf((x - true_mean) / (true_sigma * np.sqrt(2))))\n",
    "    \n",
    "    PDF_true.discretize(cdf, mode = \"cdf\")\n",
    "    PDF_true.compute_stats()\n",
    "    discrete_BT_loss += [PDF_true.BT_dist(PDF)]    \n",
    "    discrete_KL_loss += [PDF_true.KL_div(PDF)]\n",
    "\n",
    "discrete_BT_loss = np.array(discrete_BT_loss)\n",
    "discrete_KL_loss = np.array(discrete_KL_loss)\n",
    "\n",
    "### Extract statistics from MultiResolutionPDF\n",
    "\n",
    "mean_arr = []\n",
    "mode_arr = []\n",
    "sigma_arr = []\n",
    "moment_3_arr = []\n",
    "moment_4_arr = []\n",
    "\n",
    "num_commas = full_series.count(',')\n",
    "for comma_idx in range(num_commas):\n",
    "    PDF_list[comma_idx].compute_stats()\n",
    "    mean, mode, sigma = PDF_list[comma_idx].mean, PDF_list[comma_idx].mode, PDF_list[comma_idx].sigma \n",
    "    moment_3 = PDF_list[comma_idx].compute_moment(3)\n",
    "    moment_4 = PDF_list[comma_idx].compute_moment(4)\n",
    "    \n",
    "    mean_arr.append(mean)\n",
    "    mode_arr.append(mode)\n",
    "    sigma_arr.append(sigma)\n",
    "    moment_3_arr.append(moment_3)\n",
    "    moment_4_arr.append(moment_4)\n",
    "\n",
    "# Convert lists to numpy arrays\n",
    "mean_arr = np.array(mean_arr)\n",
    "mode_arr = np.array(mode_arr)\n",
    "sigma_arr = np.array(sigma_arr)\n",
    "moment_3_arr = np.array(moment_3_arr)\n",
    "moment_4_arr = np.array(moment_4_arr)\n",
    "kurtosis_arr = moment_4_arr / sigma_arr**4\n",
    "kurtosis_error = (kurtosis_arr-3)**2\n",
    "\n",
    "error_mean = np.abs(rescaled_true_mean_arr - mean_arr)\n",
    "error_mode = np.abs(rescaled_true_mean_arr - mode_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Plot kurtosis\n",
    "plt.figure(figsize=(7, 3), dpi = 200)\n",
    "window_size = 2\n",
    "\n",
    "top_hat_kernel = np.ones(window_size) / window_size\n",
    "averaged_kurtosis_arr = np.convolve(kurtosis_arr, top_hat_kernel, mode='valid')\n",
    "averaged_kurtosis_error = np.convolve(kurtosis_error, top_hat_kernel, mode='valid')\n",
    "\n",
    "plt.plot(np.arange(window_size//2, len(kurtosis_arr) - window_size//2 + 1), averaged_kurtosis_arr, linewidth=2, label = 'predicted kurtosis')\n",
    "# ax1.plot(kurtosis_arr)\n",
    "plt.axhline(y=3, color='r', linestyle='-', label = 'true kurtosis')\n",
    "# plt.plot(averaged_kurtosis_error, label = 'kurtosis error', c = \"black\")\n",
    "\n",
    "plt.xlabel('context length')\n",
    "plt.ylabel(r'BM kurtosis')\n",
    "plt.yscale('log')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'../figures/BM_kurtosis_temp{alpha}.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import interact\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import norm\n",
    "save_path = f\"../figures/BM_example_temp{alpha}.png\"\n",
    "### Load multiple digits to MultiResolutionPDF\n",
    "comma_locations = np.sort(np.where(np.array(list(full_series)) == ',')[0])\n",
    "time_series_rescaled = (time_series-time_series.min()) / (time_series.max()-time_series.min()) * (8.5-1.5) + 1.5\n",
    "\n",
    "plot1_log_scale = 0\n",
    "log_scale = 1\n",
    "truth_PDF = 0\n",
    "# final_state = 709\n",
    "final_state = None\n",
    "\n",
    "### Plot distribution before ith comma\n",
    "def digiprob_plotter(comma_idx=1):\n",
    "    if comma_idx == 0:\n",
    "        start_idx = 0\n",
    "    else:\n",
    "        start_idx = comma_locations[comma_idx-1]+1\n",
    "    if truth_PDF:\n",
    "        fig, axs = plt.subplots(3, 1, figsize=(8, 5), dpi = 200)\n",
    "    else:\n",
    "        fig, axs = plt.subplots(2, 1, figsize=(8, 10/3), dpi = 200)\n",
    "    # Adjust the horizontal space between subplots\n",
    "    plt.subplots_adjust(hspace=0.7)\n",
    "    # Plot the full array with a marker on the selected value\n",
    "    if final_state is not None:\n",
    "        time_series_plot = time_series_rescaled[:final_state+1]\n",
    "        axs[0].set_xlim(-10, final_state+10)\n",
    "    else:\n",
    "        time_series_plot = time_series_rescaled\n",
    "    axs[0].plot(time_series_plot[:-1], marker='o', color='black', markersize=2, lw = '0.1', label = \"observation\")\n",
    "    axs[0].scatter(comma_idx, time_series_plot[comma_idx], color='r', marker='o', label = \"prediction\")\n",
    "    axs[0].set_xlabel('context lenght')\n",
    "    axs[0].set_ylabel(r'rescaled $x$')\n",
    "    \n",
    "    if plot1_log_scale:\n",
    "        axs[0].set_yscale('log')\n",
    "        \n",
    "    # Plot softmax distributions for each digit\n",
    "    axs[1].set_ylabel(\"probability density\")\n",
    "    # axs[1].set_title(full_series[start_idx-30:start_idx] + \"?\")      \n",
    "    PDF_list[comma_idx].compute_stats()\n",
    "    PDF_list[comma_idx].plot(ax = axs[1], log_scale=log_scale, statistic = False)\n",
    "    if truth_PDF:\n",
    "        PDF_true_list[comma_idx].plot(ax = axs[2], log_scale=log_scale, statistic = False)\n",
    "        axs[2].set_title('discretized truth')\n",
    "        axs[2].set_xlabel(\"Digit\")\n",
    "    \n",
    "    # characterizing ground truth distribution\n",
    "    true_mean = rescaled_true_mean_arr[comma_idx]\n",
    "    true_sigma = rescaled_true_sigma_arr[comma_idx]\n",
    "    if true_sigma == 0:\n",
    "        axs[1].vlines(true_mean, 0, np.max(PDF_list[comma_idx].bin_height_arr), color='r', label='Truth', lw = 3, alpha = 0.7)\n",
    "    else:\n",
    "        x_values = np.linspace(0, 10, 300)\n",
    "        gaussian = norm.pdf(x_values, true_mean, true_sigma)\n",
    "        axs[1].plot(x_values, gaussian, color = 'r', label = 'Truth', lw = 3, alpha = 0.7)\n",
    "        # axs[1].vlines(true_mean, 0, np.max(gaussian), color = 'r')\n",
    "    # axs[1].set_ylim(np.min(pdf.bin_height_arr), np.max(gaussian)*1.7)\n",
    "    axs[1].set_xlabel(r'rescaled $x$')\n",
    "    axs[1].bar([0], [0], color='dodgerblue', label='LLM Prediction')\n",
    "    axs[1].set_xlim(0,10)\n",
    "    # axs[1].set_ylim(0,5)\n",
    "    axs[0].legend()\n",
    "    axs[1].legend()\n",
    "    if log_scale:\n",
    "        axs[1].set_ylim(0.005,10)\n",
    "        if truth_PDF:\n",
    "            axs[2].set_ylim(0.0005,10)\n",
    "    if final_state is not None: \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(save_path)\n",
    "\n",
    "# Adjust the range of the slider to match the number of commas in the series\n",
    "num_commas = full_series.count(',')\n",
    "if final_state is not None: \n",
    "    interact(digiprob_plotter, comma_idx=final_state)\n",
    "else:\n",
    "    interact(digiprob_plotter, comma_idx=(1, num_commas-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import interact\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import norm\n",
    "import copy\n",
    "\n",
    "\n",
    "### Load multiple digits to MultiResolutionPDF\n",
    "comma_locations = np.sort(np.where(np.array(list(full_series)) == ',')[0])\n",
    "time_series_rescaled = (time_series-time_series.min()) / (time_series.max()-time_series.min()) * (8.5-1.5) + 1.5\n",
    "\n",
    "plot1_log_scale = 0\n",
    "log_scale = 1\n",
    "temp_list = [1]\n",
    "final_state = None\n",
    "filenames = []\n",
    "### Plot distribution before ith comma\n",
    "def digiprob_plotter(comma_idx=1):\n",
    "    if comma_idx == 0:\n",
    "        start_idx = 0\n",
    "    else:\n",
    "        start_idx = comma_locations[comma_idx-1]+1\n",
    "\n",
    "    fig, axs = plt.subplots(1+len(temp_list), 1, figsize=(8, 5/3*(1+len(temp_list))), dpi = 200)\n",
    "    # Adjust the horizontal space between subplots\n",
    "    plt.subplots_adjust(hspace=0.7)\n",
    "    # Plot the full array with a marker on the selected value\n",
    "    if final_state is not None:\n",
    "        time_series_plot = time_series_rescaled[:final_state+1]\n",
    "    else:\n",
    "        time_series_plot = time_series_rescaled\n",
    "    # axs[0].scatter(comma_idx, time_series_plot[comma_idx], color='r', marker='o', label = \"prediction\")\n",
    "    # axs[0].plot(time_series_plot[:-1], marker='o', color='black', markersize=2, lw = '0.1', label = \"observation\")\n",
    "    axs[0].plot(time_series_plot[:-1], marker='o', color='black', markersize=2, lw='0.1', label=\"observation\", zorder=1)\n",
    "    axs[0].scatter(comma_idx, time_series_plot[comma_idx], color='r', marker='o', label=\"prediction\", zorder=2)\n",
    "    axs[0].set_xlabel('context lenght')\n",
    "    axs[0].set_ylabel(r'rescaled $x$')\n",
    "    if final_state is not None:\n",
    "        axs[0].set_xlim(-10, final_state+10)\n",
    "    if plot1_log_scale:\n",
    "        axs[0].set_yscale('log')\n",
    "        \n",
    "        \n",
    "    for i, temp in enumerate(temp_list):\n",
    "    # Plot softmax distributions for each digit\n",
    "        axs[i+1].set_ylabel(\"probability density\")\n",
    "        if len(temp_list) > 1:\n",
    "            axs[i+1].set_title(f\"LLM temperature = {temp}\") \n",
    "        \n",
    "        PDF_copied = copy.deepcopy(PDF_list[comma_idx])\n",
    "        PDF_copied.rescale_temperature(temp)\n",
    "        PDF_copied.compute_stats()\n",
    "        PDF_copied.plot(ax = axs[i+1], log_scale=log_scale, statistic = False)\n",
    "        if log_scale:\n",
    "            axs[1].set_ylim(0.005,10)\n",
    "\n",
    "        # characterizing ground truth distribution\n",
    "        true_mean = rescaled_true_mean_arr[comma_idx]\n",
    "        true_sigma = rescaled_true_sigma_arr[comma_idx]\n",
    "        if true_sigma == 0:\n",
    "            axs[i+1].vlines(true_mean, 0, np.max(PDF_list[comma_idx].bin_height_arr), color='r', label='Truth', lw = 3, alpha = 0.7)\n",
    "        else:\n",
    "            x_values = np.linspace(0, 10, 300)\n",
    "            gaussian = norm.pdf(x_values, true_mean, true_sigma)\n",
    "            axs[i+1].plot(x_values, gaussian, color = 'r', lw = 3, alpha = 0.7)\n",
    "\n",
    "        # axs[1].bar([0], [0], lw = 3, color='lightseagreen', label='bin of width 1')\n",
    "        # axs[1].bar([0], [0], lw = 3, color='blue', label='bin of width 0.01')\n",
    "        axs[1].bar([0], [0], lw = 3, color='dodgerblue', label='LLM prediction')\n",
    "        axs[1].plot([0], [0], color='r', label='truth')\n",
    "        \n",
    "        axs[i+1].set_xlabel(r'rescaled $x$')\n",
    "        axs[i+1].legend()\n",
    "        axs[i+1].set_xlim(0,10)\n",
    "        if len(temp_list) > 1:\n",
    "            axs[i+1].set_ylim(0,2.6)    \n",
    "        \n",
    "\n",
    "    axs[0].legend(loc=\"lower left\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    save_path = f\"../figures/BM_example_snapshot_{comma_idx}.png\"\n",
    "    filenames.append(save_path)\n",
    "    plt.savefig(save_path)\n",
    "\n",
    "# Adjust the range of the slider to match the number of commas in the series\n",
    "num_commas = full_series.count(',')\n",
    "snapshots = [1,2,3,4,5,6,10,100,200,300,400,500,600,700,800,900,986]\n",
    "for snapshot in snapshots:\n",
    "    interact(digiprob_plotter, comma_idx=snapshot)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a GIF using snapshot made\n",
    "import imageio.v2 as imageio\n",
    "\n",
    "with imageio.get_writer('../figures/BM_snapshots.gif', mode='I', duration=500, loop=0) as writer:\n",
    "    for filename in filenames:\n",
    "        image = imageio.imread(filename)\n",
    "        writer.append_data(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LLM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
